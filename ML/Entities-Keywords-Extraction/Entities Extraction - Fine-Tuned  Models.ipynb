{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Entities Extraction using Watson NLP"]},{"cell_type":"markdown","metadata":{},"source":["## Use Case\n","\n","\n","This notebook showcases the process of extracting entities through the utilization of  fine-tuning custom entities using Watson NLP. The primary objective of entity extraction is to automatically identify and classify specific entities such as people, dates, locations, and more.\n","\n","## What you'll learn in this notebook\n","\n","Watson NLP implements state-of-the-art classification algorithms from three different families: \n","- Classic machine learning using CRF (Conditional Random Field)\n","- Deep learning using BiLSTM (Bidirectional Long Short Term Memory)\n","- SIRE (Statistical Information and Relation Extraction) Watson NLP Model\n","\n","In this notebook, you'll learn how to:\n","\n","- **Prepare your data** so that it can be used as training data for the Watson NLP classification algorithms.\n","- **Train a custom CRF model** using `watson_nlp.workflows.entity_mentions.SIRE`.\n","- **Train a BiLSTM** using `watson_nlp.blocks.entity_mentions.BiLSTM`.\n","- **Store and load models** as an asset of a Watson Studio project.\n","\n","## Table of Contents\n","\n","1. [Before You Start](#beforeYouStart)\n","1.  [Preparing Sample Data set](#prepareTraining)\n","1.  [Fine-Tune Models for Entities Extraction](#buildModel)\n","    1. [SIRE Training](#sire)\n","    1. [BiLSTM Training](#bilstm)\n","1.  [Summary](#summary)"]},{"cell_type":"markdown","metadata":{},"source":["##### <a id=\"beforeYouStart\"></a>\n","## 1. Before You Start\n","\n","<div class=\"alert alert-block alert-danger\">\n","<b>Stop kernel of other notebooks.</b></div>\n","\n","**Note:** If you have other notebooks currently running with the _Default Python 3.x environment, **stop their kernels** before running this notebook. All these notebooks share the same runtime environment, and if they are running in parallel, you may encounter memory issues. To stop the kernel of another notebook, open that notebook, and select _File > Stop Kernel_.\n","\n","<div class=\"alert alert-block alert-warning\">\n","<b>Set Project token.</b></div>\n","\n","Before you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n","\n","When this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n","\n","![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n","\n","<div class=\"alert alert-block alert-info\">\n","<b>Tip:</b> Cell execution</div>\n","\n","Note that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting faker\n","  Downloading Faker-17.5.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from faker) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.10-CUDA/lib/python3.10/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n","Installing collected packages: faker\n","Successfully installed faker-17.5.0\n"]}],"source":["!pip install faker"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["import json\n","import pandas as pd\n","import watson_nlp\n","from faker import Faker\n","import random\n","import string\n","from watson_nlp import data_model as dm\n","from watson_nlp.toolkit.entity_mentions_utils import prepare_train_from_json, create_iob_labels"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# Silence Tensorflow warnings\n","import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')\n","tf.autograph.set_verbosity(0)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Load a syntax model to split the text into sentences and tokens\n","syntax_model = watson_nlp.load(watson_nlp.download('syntax_izumo_en_stock'))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"prepareTraining\"></a>\n","## 2. Preparing Sample Data Set"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing the training data for fine-tune the model with Custom Entities.\n","\n","* Language \n","* Nationality \n","* periodical_set\n","* Festival\n","* Color\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["#Generate the dataset using faker\n","fake = Faker(locale='en_US')\n","\n","def format_data():\n","\n","    language = fake.language_name()\n","    nationality = fake.random_element(elements=('American', 'British', 'Canadian', 'Chinese', 'French', 'German', 'Italian', 'Japanese', 'Korean', 'Mexican', 'Russian', 'Spanish'))\n","    periodical_set = fake.random_element(['daily', 'biannually', 'hebdomadally', 'fortnightly', 'monthly', 'Weekly','quarterly', 'semiannually', 'yearly','every week', 'each afternoon', 'on Fridays', 'at night', 'on Wednesdays', 'on weekends'])\n","    festival = random.choice([\"New Year\",\"Super Bowl Sunday\",\"Valentine day\",\"Presidents day\",\"St. Patrick\",\"Easter\",\"Memorial Day\",\"Independence Day\",\"Labor Day\",\"Columbus Day\",\"Halloween\",\"Veterans Day\",\"Thanksgiving\",\"Christmas\"])\n","    color = fake.color_name()\n","    \n","    text1= \"Their %s friend recently started learning %s, they can prepare it %s, tomorrow they have holiday due to %s, we can go for drive in my %s car.\"%(nationality,language,periodical_set,festival,color)\n","    text2=\"my %s neighbour can speak %s, they can practice %s. We can meet them on %s with %s book.\"%(nationality,language,periodical_set,festival, color)\n","\n","    text = random.choice([text1, text2])\n","    \n","    color_begin = text.find(color)\n","    color_end = color_begin + len(color)\n","\n","    nationality_begin = text.find(nationality)\n","    nationality_end = nationality_begin + len(nationality)\n","  \n","    language_begin = text.find(language)\n","    language_end = language_begin + len(language)\n","    \n","    festival_begin = text.find(festival)\n","    festival_end = festival_begin + len(festival)\n","    \n","    periodical_set_begin = text.find(periodical_set)\n","    periodical_set_end = periodical_set_begin + len(periodical_set)\n","\n","    data = {\n","                \"text\": text,\n","                \"mentions\": [\n","                    {\n","                        \"location\": {\n","                            \"begin\": color_begin,\n","                            \"end\": color_end\n","                        },\n","                        \"text\": color,\n","                        \"type\": \"color\"\n","                    },                    \n","                    {\n","                        \"location\": {\n","                            \"begin\": nationality_begin,\n","                            \"end\": nationality_end\n","                        },\n","                        \"text\": nationality,\n","                        \"type\": \"nationality\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": language_begin,\n","                            \"end\": language_end\n","                        },\n","                        \"text\": language,\n","                        \"type\": \"language\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": festival_begin,\n","                            \"end\": festival_end\n","                        },\n","                        \"text\": festival,\n","                        \"type\": \"festival\"\n","                    },\n","                    {\n","                        \"location\": {\n","                            \"begin\": periodical_set_begin,\n","                            \"end\": periodical_set_end\n","                        },\n","                        \"text\": periodical_set,\n","                        \"type\": \"periodical_set\"\n","                    }\n","                ]   \n","            }\n","    \n","    return data"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["{'text': 'Their Korean friend recently started learning Marshallese, they can prepare it every week, tomorrow they have holiday due to Valentine day, we can go for drive in my DarkGoldenRod car.',\n"," 'mentions': [{'location': {'begin': 166, 'end': 179},\n","   'text': 'DarkGoldenRod',\n","   'type': 'color'},\n","  {'location': {'begin': 6, 'end': 12},\n","   'text': 'Korean',\n","   'type': 'nationality'},\n","  {'location': {'begin': 46, 'end': 57},\n","   'text': 'Marshallese',\n","   'type': 'language'},\n","  {'location': {'begin': 125, 'end': 138},\n","   'text': 'Valentine day',\n","   'type': 'festival'},\n","  {'location': {'begin': 79, 'end': 89},\n","   'text': 'every week',\n","   'type': 'periodical_set'}]}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["#Sample dataset\n","format_data()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'custom_entity_train_data.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': '8722380f-01db-41a1-9fec-8e4a1befe2d9'}"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Custom Entities\n","train_list_faker = []\n","for i in range(0, 30000):\n","    train_list_faker.append(format_data())\n","\n","with open('custom_entity_train_data.json', 'w') as f:\n","    json.dump(train_list_faker, f)\n","project.save_data('custom_entity_train_data.json', data=json.dumps(train_list_faker), overwrite=True)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'custom_entity_test_data.json',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'e1e7eb51-6182-411b-92a0-cdb9951ee6eb'}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#Prepared and store Training dataset for Custom Entities\n","test_list_faker = []\n","for i in range(0, 1000):\n","    test_list_faker.append(format_data())\n","\n","with open('custom_entity_test_data.json', 'w') as f:\n","    json.dump(test_list_faker, f)\n","project.save_data('custom_entity_test_data.json', data=json.dumps(test_list_faker), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Since the data is already formatted correctly, the following process is needed to read the JSON data files from Watson Studio project assets and save them to the runtime working directory where they will be used as input for training the models."]},{"cell_type":"markdown","metadata":{},"source":["The text inputs will be converted into a streaming array where the text is broken down by the syntax model."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["train_data = dm.DataStream.from_json_array(\"custom_entity_train_data.json\")\n","train_iob_stream = prepare_train_from_json(train_data, syntax_model)\n","dev_data = dm.DataStream.from_json_array(\"custom_entity_test_data.json\")\n","dev_iob_stream = prepare_train_from_json(dev_data, syntax_model)\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"FTbuildModel\"></a>\n","## 3. Fine-Tune Models\n","\n","Entity extraction uses the entity-mentions block to encapsulate algorithms for the task of extracting mentions of entities (person, organizations, dates, locations,...) from the input text. The blocks and workflows offer implementations of strong entity extraction algorithms from each of the four families: rule-based, classic ML, deep-learning and transformers."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"sire\"></a>\n","### 3.1 SIRE Training"]},{"cell_type":"markdown","metadata":{},"source":["You can train SIRE models using either CRF & Maximum Entropy template as base models. Between the two, CRF based template takes longer to train but gives better results.\n","\n","These algorithms accept a set of featured in the form of dictionaries and regular expressions. A set of predefined feature extractors are provided for multiple languages, and you can also define your own features.\n","\n","`labeled_entity_mentions` : Path to a collection of labeled data (.json) or loaded DataStream of JSONs, which prepared above in [Preparing Sample Data Set](#prepareTraining). `/home/wsuser/work/` is home directory."]},{"cell_type":"code","execution_count":3,"metadata":{"scrolled":true},"outputs":[],"source":["#help(watson_nlp.workflows.entity_mentions.SIRE)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Download the algorithm template\n","mentions_train_template = watson_nlp.load(watson_nlp.download('file_path_entity-mentions_sire_multi_template-crf'))\n","# Download the feature extractor\n","default_feature_extractor = watson_nlp.load(watson_nlp.download('feature-extractor_rbr_entity-mentions_sire_en_stock'))"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n","Get Feature str 27516\n","Done get feature str 27516\n","done. [53\u001b[33mg\u001b[0m1001\u001b[33mm\u001b[0m776\u001b[33mk\u001b[0m,12\u001b[33mg\u001b[0m916\u001b[33mm\u001b[0m864\u001b[33mk\u001b[0m]\n","gramSize = 2\n","number of processes: 5\n","Initial processing:  (# of words: 876792, # of sentences: 46439)\n","senIndex[1] = 9259, wordIndex = 175364\n","senIndex[2] = 18510, wordIndex = 350723\n","senIndex[3] = 27744, wordIndex = 526086\n","senIndex[4] = 37113, wordIndex = 701443\n","senIndex[5] = 46438, wordIndex = 876792\n","\u001b[32m[ME_CRF::scaleModel]\u001b[0m Updater -- l1=\u001b[32m0.1\u001b[0m, l2=\u001b[32m0.005\u001b[0m, history size=\u001b[32m5\u001b[0m, progress windows size \u001b[32m20\u001b[0m\n"," Iteration           Obj             WErr                         Timing       %Eff        Per thread timing\n","              1894685.49      5.67/ 75.40             E:3.19 s, M:0.02 s.       1.00 [m:3.17, M:3.18, av:3.18]\n","         0   839323.40     22.13/100.00             E:3.11 s, M:0.01 s.       1.00 [m:3.09, M:3.11, av:3.11]\n","         1   419737.71     21.55/100.00             E:3.20 s, M:0.03 s.       1.00 [m:3.16, M:3.18, av:3.18]\n","         2   208972.68      6.03/ 68.16             E:3.13 s, M:0.02 s.       1.00 [m:3.11, M:3.13, av:3.13]\n","         3    87187.29      1.25/ 21.40             E:3.17 s, M:0.02 s.       1.00 [m:3.15, M:3.17, av:3.17]\n","         4    47514.68      0.30/  4.66             E:3.16 s, M:0.02 s.       1.00 [m:3.14, M:3.16, av:3.16]\n","         5    26115.00      0.30/  4.66             E:3.11 s, M:0.02 s.       1.00 [m:3.09, M:3.11, av:3.11]\n","         6    17400.20      0.13/  1.84             E:3.21 s, M:0.03 s.       1.00 [m:3.17, M:3.20, av:3.19]\n","         7     7579.52      0.07/  0.78             E:3.16 s, M:0.03 s.       1.00 [m:3.14, M:3.16, av:3.16]\n","         8     5377.27      0.02/  0.23             E:3.19 s, M:0.02 s.       1.00 [m:3.17, M:3.19, av:3.19]\n","         9     4640.94      0.02/  0.23             E:3.12 s, M:0.02 s.       1.00 [m:3.09, M:3.12, av:3.11]\n","        10     4069.50      0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.10, M:3.13, av:3.13]\n","        11     3112.31      0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.11, M:3.13, av:3.12]\n","        12     2670.06      0.02/  0.23             E:3.15 s, M:0.03 s.       1.00 [m:3.12, M:3.14, av:3.14]\n","        13     2196.08      0.02/  0.23             E:3.18 s, M:0.02 s.       1.00 [m:3.13, M:3.16, av:3.16]\n","        14     1853.33      0.02/  0.23             E:3.18 s, M:0.02 s.       1.00 [m:3.16, M:3.18, av:3.18]\n","        15     1646.72      0.02/  0.23             E:3.09 s, M:0.02 s.       1.00 [m:3.07, M:3.09, av:3.08]\n","        16     1532.36      0.02/  0.23             E:3.17 s, M:0.02 s.       1.00 [m:3.16, M:3.17, av:3.17]\n","        17     1446.67      0.02/  0.23             E:3.13 s, M:0.03 s.       1.00 [m:3.11, M:3.13, av:3.12]\n","        18     1373.03      0.02/  0.23             E:3.16 s, M:0.03 s.       1.00 [m:3.12, M:3.14, av:3.13]\n","        19     1288.13      0.02/  0.23             E:3.14 s, M:0.02 s.       1.00 [m:3.12, M:3.14, av:3.14]\n","        20     1230.85      0.02/  0.23             E:3.17 s, M:0.02 s.       1.00 [m:3.15, M:3.17, av:3.17]\n","        21     1205.48      0.02/  0.23             E:3.12 s, M:0.02 s.       1.00 [m:3.09, M:3.12, av:3.12]\n","        22     1193.09      0.02/  0.23             E:3.12 s, M:0.02 s.       1.00 [m:3.10, M:3.11, av:3.11]\n","        23     1178.39      0.02/  0.23             E:3.17 s, M:0.03 s.       1.00 [m:3.14, M:3.17, av:3.17]\n","        24     1173.31      0.02/  0.23             E:3.17 s, M:0.02 s.       1.00 [m:3.15, M:3.17, av:3.17]\n","        25     1162.75      0.02/  0.23             E:3.13 s, M:0.03 s.       1.00 [m:3.11, M:3.13, av:3.13]\n","        26     1151.09      0.02/  0.23             E:3.30 s, M:0.02 s.       1.00 [m:3.27, M:3.30, av:3.29]\n","        27     1145.16      0.02/  0.23             E:3.11 s, M:0.03 s.       1.00 [m:3.09, M:3.11, av:3.11]\n","        28     1141.36      0.02/  0.23             E:3.12 s, M:0.02 s.       1.00 [m:3.10, M:3.12, av:3.12]\n","        29     1138.37      0.02/  0.23             E:3.18 s, M:0.02 s.       1.00 [m:3.15, M:3.18, av:3.17]\n","        30     1136.09      0.02/  0.23             E:3.12 s, M:0.02 s.       1.00 [m:3.10, M:3.12, av:3.11]\n","        31     1133.49      0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.10, M:3.13, av:3.12]\n","        32     1131.29      0.02/  0.23             E:3.12 s, M:0.02 s.       1.00 [m:3.10, M:3.12, av:3.12]\n","        33     1129.76      0.02/  0.23             E:3.15 s, M:0.02 s.       1.00 [m:3.12, M:3.15, av:3.14]\n","        34     1127.26      0.02/  0.23             E:3.12 s, M:0.03 s.       1.00 [m:3.09, M:3.12, av:3.12]\n","        35     1125.24      0.02/  0.23             E:3.14 s, M:0.02 s.       1.00 [m:3.12, M:3.14, av:3.14]\n","        36     1120.20      0.02/  0.23             E:3.18 s, M:0.02 s.       1.00 [m:3.15, M:3.18, av:3.17]\n","        37     1115.61      0.02/  0.23             E:3.14 s, M:0.02 s.       1.00 [m:3.12, M:3.14, av:3.14]\n","        38     1107.67      0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.12, M:3.13, av:3.13]\n","        39     1097.67      0.02/  0.23             E:3.14 s, M:0.02 s.       1.00 [m:3.11, M:3.14, av:3.14]\n","        40     1088.54      0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.10, M:3.13, av:3.13]\n","        41     1082.80      0.02/  0.23             E:3.24 s, M:0.02 s.       1.00 [m:3.20, M:3.24, av:3.24]\n","        42     1077.05      0.02/  0.23             E:3.18 s, M:0.03 s.       1.00 [m:3.15, M:3.18, av:3.18]\n","        43     1075.23      0.02/  0.23             E:3.16 s, M:0.02 s.       1.00 [m:3.14, M:3.16, av:3.15]\n","        44     1073.30      0.02/  0.23             E:3.15 s, M:0.02 s.       1.00 [m:3.12, M:3.15, av:3.15]\n","        45     1072.23      0.02/  0.23             E:3.20 s, M:0.02 s.       1.00 [m:3.17, M:3.20, av:3.19]\n","        46     1071.66      0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.12, M:3.13, av:3.13]\n","        47     1071.14     "]}],"source":["# Train the model\n","sire_custom = watson_nlp.workflows.entity_mentions.SIRE.train(syntax_model=syntax_model,\n","                                                              labeled_entity_mentions='/home/wsuser/work/', \n","                                                              model_language='en', \n","                                                              template_resource=mentions_train_template, \n","                                                              feature_extractors=[default_feature_extractor], \n","                                                              l1=0.1, \n","                                                              l2=0.005, \n","                                                              num_epochs=50, \n","                                                              num_workers=5)"]},{"cell_type":"markdown","metadata":{},"source":["The following code will save the custom model to Watson Studio by using the project library."]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[" 0.02/  0.23             E:3.13 s, M:0.02 s.       1.00 [m:3.10, M:3.13, av:3.13]\n","        48     1070.96      0.02/  0.23             E:3.14 s, M:0.02 s.       1.00 [m:3.12, M:3.14, av:3.14]\n","        49     1070.53      0.02/  0.23             E:3.14 s, M:0.02 s.       1.00 [m:3.12, M:3.14, av:3.14]\n","    Thread     Total      Wait Effective      %Eff         #Sents/sec\n","         0    160.13      0.00    160.13      1.00             2956.83\n","         1    160.04      0.00    160.04      1.00             2960.90\n","         2    160.19      0.00    160.19      1.00             2951.05\n","         3    160.11      0.00    160.11      1.00             2971.18\n","         4    160.18      0.00    160.18      1.00             2950.29\n","Parent: the end!\n","Initializing viterbi classifier\n","\u001b[32m[MEVitClassifier::initModel]\u001b[0m MEVitClassifier initialized.\n","\u001b[32m[MEVitClassifier2::initModel]\u001b[0m model initialized.\n","Saved 2353 features.\n"]},{"data":{"text/plain":["{'file_name': 'entity_sire_custom',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'fe0ac856-5fb9-4a00-8e1c-87448d3c9ce1'}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Save the model\n","project.save_data('entity_sire_custom', data=sire_custom.as_file_like_object(), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Let's run the model on one example input from the dev dataset."]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["'my Chinese neighbour can speak Arabic, they can practice fortnightly. We can meet them on Columbus Day with Silver book.'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["text = pd.read_json('custom_entity_test_data.json')['text'][3]\n","text"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["{\n","  \"mentions\": [\n","    {\n","      \"span\": {\n","        \"begin\": 3,\n","        \"end\": 10,\n","        \"text\": \"Chinese\"\n","      },\n","      \"type\": \"nationality\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9972540536035641,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 31,\n","        \"end\": 37,\n","        \"text\": \"Arabic\"\n","      },\n","      \"type\": \"language\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9999835617867643,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 57,\n","        \"end\": 68,\n","        \"text\": \"fortnightly\"\n","      },\n","      \"type\": \"periodical_set\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9999952747452828,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 90,\n","        \"end\": 102,\n","        \"text\": \"Columbus Day\"\n","      },\n","      \"type\": \"festival\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.9999672551278073,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 108,\n","        \"end\": 114,\n","        \"text\": \"Silver\"\n","      },\n","      \"type\": \"color\",\n","      \"producer_id\": null,\n","      \"confidence\": 0.7077578736747369,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    }\n","  ],\n","  \"producer_id\": {\n","    \"name\": \"Entity-Mentions SIRE Workflow\",\n","    \"version\": \"0.0.1\"\n","  }\n","}"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# Run the model\n","sire_result = sire_custom.run(text)\n","sire_result"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"bilstm\"></a>\n","### 3.2 BiLSTM Training"]},{"cell_type":"markdown","metadata":{},"source":["The deep-learning algorithm used in this block performs sequence labelling based on the BiLSTM architecture followed by a CRF layer. It uses GloVe embeddings as features."]},{"cell_type":"code","execution_count":26,"metadata":{"scrolled":true},"outputs":[],"source":["#help(watson_nlp.blocks.entity_mentions.BiLSTM)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# Download the GloVe model to be used as embeddings in the BiLSTM\n","glove_model = watson_nlp.load(watson_nlp.download('embedding_glove_en_stock'))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1404/1404 [==============================] - 31s 22ms/step - loss: 0.0414 - val_loss: 0.0013\n","1404/1404 [==============================] - 24s 17ms/step - loss: 0.0016 - val_loss: 6.7931e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 0.0011 - val_loss: 5.4319e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 9.9157e-04 - val_loss: 5.0306e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 9.4649e-04 - val_loss: 4.8855e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 9.0887e-04 - val_loss: 4.8128e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.5313e-04 - val_loss: 4.7000e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.5571e-04 - val_loss: 4.5588e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.8324e-04 - val_loss: 4.5568e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.1514e-04 - val_loss: 4.5233e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.2011e-04 - val_loss: 4.5901e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.2202e-04 - val_loss: 4.5596e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.4231e-04 - val_loss: 4.6354e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.1633e-04 - val_loss: 4.5498e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.1994e-04 - val_loss: 4.5441e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.2263e-04 - val_loss: 4.5664e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.1604e-04 - val_loss: 4.5521e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.9415e-04 - val_loss: 4.6040e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.8272e-04 - val_loss: 4.5192e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.9780e-04 - val_loss: 4.5646e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.8582e-04 - val_loss: 4.5553e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.9550e-04 - val_loss: 4.4957e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.1716e-04 - val_loss: 4.4949e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.8253e-04 - val_loss: 4.5345e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.7628e-04 - val_loss: 4.4959e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.3463e-04 - val_loss: 4.5386e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 8.0551e-04 - val_loss: 4.5541e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.7941e-04 - val_loss: 4.4857e-04\n","1404/1404 [==============================] - 25s 18ms/step - loss: 7.8330e-04 - val_loss: 4.5647e-04\n","1404/1404 [==============================] - 24s 17ms/step - loss: 7.8980e-04 - val_loss: 4.4284e-04\n"]}],"source":["# Train BILSTM Model for Educational details entity\n","bilstm_custom = watson_nlp.blocks.entity_mentions.BiLSTM.train(train_iob_stream,\n","                                                              dev_iob_stream,\n","                                                              glove_model.embedding,\n","                                                              num_train_epochs=5)"]},{"cell_type":"markdown","metadata":{},"source":["If we want to save the trained block model as a workflow, to be run with raw text later, we can use the following code snippet to do so"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["#Save the Trained block model as a workflow model \n","from watson_nlp.workflows.entity_mentions.bilstm import BiLSTM \n","\n","mentions_workflow = BiLSTM(syntax_model, bilstm_custom)\n"]},{"cell_type":"markdown","metadata":{},"source":["The following code will save the custom model to Watson Studio by using the project library."]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["{'file_name': 'Entity_workflow_bilstm_custom',\n"," 'message': 'File saved to project storage.',\n"," 'bucket_name': 'watsoncore-donotdelete-pr-olkxvfa8bk0pb1',\n"," 'asset_id': 'fc7ff781-8e34-4ecc-b30b-bf1afcd9a5ae'}"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Save the model\n","project.save_data('Entity_workflow_bilstm_custom', data=mentions_workflow.as_file_like_object(), overwrite=True)"]},{"cell_type":"markdown","metadata":{},"source":["Let's run the model on one example input."]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["{\n","  \"mentions\": [\n","    {\n","      \"span\": {\n","        \"begin\": 3,\n","        \"end\": 10,\n","        \"text\": \"Chinese\"\n","      },\n","      \"type\": \"nationality\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 0.9999990463256836,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 31,\n","        \"end\": 37,\n","        \"text\": \"Arabic\"\n","      },\n","      \"type\": \"language\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 0.999930739402771,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 57,\n","        \"end\": 68,\n","        \"text\": \"fortnightly\"\n","      },\n","      \"type\": \"periodical_set\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 1.0,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 90,\n","        \"end\": 102,\n","        \"text\": \"Columbus Day\"\n","      },\n","      \"type\": \"festival\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 1.0,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    },\n","    {\n","      \"span\": {\n","        \"begin\": 108,\n","        \"end\": 114,\n","        \"text\": \"Silver\"\n","      },\n","      \"type\": \"color\",\n","      \"producer_id\": {\n","        \"name\": \"BiLSTM Entity Mentions\",\n","        \"version\": \"1.0.0\"\n","      },\n","      \"confidence\": 1.0,\n","      \"mention_type\": \"MENTT_UNSET\",\n","      \"mention_class\": \"MENTC_UNSET\",\n","      \"role\": \"\"\n","    }\n","  ],\n","  \"producer_id\": {\n","    \"name\": \"BiLSTM Entity Mentions Workflow\",\n","    \"version\": \"1.0.0\"\n","  }\n","}"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["# Run the BILSTM workflow model\n","#syntax_result = syntax_model.run(text)\n","bilstm_result = mentions_workflow.run(text)\n","\n","bilstm_result"]},{"cell_type":"markdown","metadata":{},"source":["Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation.\n","\n","Watson NLP includes methods for quality testing supported models. Given a model and test data, a quality report can be generated. The following example includes the steps required to generate a quality report for a BiLSTM entity mention extactor model. The same example can be applied to any entity mention extractor model."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"summary\"></a>\n","## 4. Summary"]},{"cell_type":"markdown","metadata":{},"source":["<span style=\"color:blue\">This notebook shows you how to use the Watson NLP library and how quickly and easily you can train and run different entities extraction models using Watson NLP. </span>"]},{"cell_type":"markdown","metadata":{},"source":["Please note that this content is made available to foster Embedded AI technology adoption. The content may include systems & methods pending patent with USPTO and protected under US Patent Laws. For redistribution of this content, IBM will use release process. For any questions please log an issue in the [GitHub](https://github.com/ibm-build-labs/Watson-NLP). \n","\n","Developed by IBM Build Lab \n","\n","Copyright - 2023 IBM Corporation "]}],"metadata":{"kernelspec":{"display_name":"Python 3.10 + GPU","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":1}
